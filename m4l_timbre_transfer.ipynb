{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "m4l_timbre_transfer.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkMl1mjCOpdl",
        "colab_type": "text"
      },
      "source": [
        "# M4L - Timbre Transfer \n",
        "\n",
        "\"Have fun! And please feel free to hack this notebook to make your own creative interactions.“[- Magenta](https://colab.research.google.com/github/magenta/ddsp/blob/master/ddsp/colab/demos/timbre_transfer.ipynb)\n",
        "\n",
        "This is such a hacked notebook. It contains a loop that searches a Google Drive folder for new files to process, and have a m4l-devices for settings and download of processed files.\n",
        "\n",
        "### Instructions for running:\n",
        "\n",
        "* Make sure to use a GPU runtime, click:  __Runtime >> Change Runtime Type >> GPU__\n",
        "* Press ▶️ on the left of each of the cells\n",
        "* View the code: Double-click any of the cells\n",
        "* Hide the code: Double click the right side of the cell\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GpXRuXAe5Mg",
        "colab_type": "text"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poW2zrzh3_h_",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install and Import\n",
        "\n",
        "#@ markdown DInstall ddsp, define some helper functions, and download the model. This transfers a lot of data and _should take a minute or two_.\n",
        "%tensorflow_version 2.x\n",
        "\n",
        "print('Installing from pip package...')\n",
        "!pip install -qU ddsp\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "# Ignore a bunch of deprecation warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import copy\n",
        "import os\n",
        "import time \n",
        "import json\n",
        "import crepe\n",
        "import ddsp\n",
        "import ddsp.training\n",
        "from ddsp.colab import colab_utils\n",
        "from ddsp.colab.colab_utils import (\n",
        "    auto_tune, detect_notes, fit_quantile_transform, \n",
        "    get_tuning_factor, download, play, record, \n",
        "    specplot, upload, DEFAULT_SAMPLE_RATE)\n",
        "import gin\n",
        "import gin\n",
        "from google.colab import files\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "# Helper Functions\n",
        "sample_rate = DEFAULT_SAMPLE_RATE  # 16000\n",
        "\n",
        "import base64\n",
        "import io\n",
        "import tempfile\n",
        "\n",
        "import ddsp\n",
        "from IPython import display\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "from pydub import AudioSegment\n",
        "from scipy.io import wavfile\n",
        "import tensorflow.compat.v2 as tf\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab import output\n",
        "download = files.download\n",
        "\n",
        "DEFAULT_SAMPLE_RATE = 16000\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import json, time\n",
        "print('Done!')\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEKrh62Ee96P",
        "colab_type": "text"
      },
      "source": [
        "##Login for authentication for Google Drive access"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Xrd_SF74WH0",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suhegPgv6CnN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Load functionality from DDSP 'Timbre Transfer Demo Notebook'\n",
        "\n",
        "Essentially copy/paste from the DDSP 'Timbre Transfer Demo Notebook', made to work for this. Added functions for file management. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_McEN8UT4WEh",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Whole lotta code\n",
        "gdID = None\n",
        "file_list = drive.ListFile({'q': \"'root' in parents and trashed=false and title = 'M4L-Timbre-Transfer-Folder'\"}).GetList()\n",
        "for file1 in file_list:\n",
        "  # print(\"FOLDER\", file1)\n",
        "  print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
        "  gdID = file1['id']\n",
        "\n",
        "\n",
        "audio = None\n",
        "audio_features = None\n",
        "audio_features_mod = None\n",
        "def p4load(fileName):\n",
        "  global audio, audio_features, audio_features_mod\n",
        "  anp, sr = load_audio(fileName)\n",
        "  print(\"anp\", anp)\n",
        "  audio = anp[np.newaxis, :]\n",
        "  specplot(audio)\n",
        "  play(audio)\n",
        "\n",
        "  # Setup the session.\n",
        "  ddsp.spectral_ops.reset_crepe()\n",
        "\n",
        "  start_time = time.time()\n",
        "  audio_features = ddsp.training.metrics.compute_audio_features(audio)\n",
        "  audio_features['loudness_db'] = audio_features['loudness_db'].astype(np.float32)\n",
        "  audio_features_mod = None\n",
        "  print('Audio features took %.1f seconds' % (time.time() - start_time))\n",
        "\n",
        "\n",
        "TRIM = -15\n",
        "\n",
        "\n",
        "#modAudio = 0;\n",
        "def load_audio(path):\n",
        "   ##3 \"\"\"Load audio into numpy array, cache it so on reload script music doesn't need to reload\"\"\"\n",
        "    # TODO : should detect format to pass sample rate when enabling mp3, 16000 for mp3\n",
        "    audio_np, unused_sr = librosa.core.load(path, sr=16000)\n",
        "    return audio_np.astype(np.float32), unused_sr\n",
        "\n",
        "# @title P4 MODEL\n",
        "    \n",
        "# model = null\n",
        "# 'Violin' #@param ['Violin', 'Flute', 'Flute2', 'Trumpet', 'Tenor_Saxophone','Upload your own (checkpoint folder as .zip)']\n",
        "# MODEL = model\n",
        "\n",
        "def p4model(m):\n",
        "    global audio_features_mod, audio, audio_features\n",
        "    global model, MODEL\n",
        "    model = m\n",
        "    MODEL = m\n",
        "    #audio_features = modified\n",
        "    GCS_CKPT_DIR = 'gs://ddsp/models/tf2'\n",
        "    print(\"m\", m, \"model\", model, \"MODEL\", MODEL)\n",
        "    if model in ('Violin', 'Flute', 'Flute2', 'Trumpet', 'Tenor_Saxophone'):\n",
        "        # Pretrained models.\n",
        "        PRETRAINED_DIR = '/content/pretrained'\n",
        "        # Copy over from gs:// for faster loading.\n",
        "        !rm -r $PRETRAINED_DIR &> /dev/null\n",
        "        !mkdir $PRETRAINED_DIR &> /dev/null\n",
        "        GCS_CKPT_DIR = 'gs://ddsp/models/tf2'\n",
        "        model_dir = os.path.join(GCS_CKPT_DIR, 'solo_%s_ckpt' % model.lower())\n",
        "        \n",
        "        !gsutil cp $model_dir/* $PRETRAINED_DIR &> /dev/null\n",
        "        model_dir = PRETRAINED_DIR\n",
        "        gin_file = os.path.join(model_dir, 'operative_config-0.gin')\n",
        "\n",
        "    # Load the dataset statistics.\n",
        "    DATASET_STATS = None\n",
        "    dataset_stats_file = os.path.join(model_dir, 'dataset_statistics.pkl')\n",
        "    print(f'Loading dataset statistics from {dataset_stats_file}')\n",
        "    try:\n",
        "      if tf.io.gfile.exists(dataset_stats_file):\n",
        "        with tf.io.gfile.GFile(dataset_stats_file, 'rb') as f:\n",
        "          DATASET_STATS = pickle.load(f)\n",
        "    except Exception as err:\n",
        "      print('Loading dataset statistics from pickle failed: {}.'.format(err))\n",
        "\n",
        "      \n",
        "    # Parse gin config,\n",
        "    with gin.unlock_config():\n",
        "      gin.parse_config_file(gin_file, skip_unknown=True)\n",
        "    \n",
        "    # Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
        "    ckpt_files = [f for f in tf.io.gfile.listdir(model_dir) if 'ckpt' in f]\n",
        "    ckpt_name = ckpt_files[0].split('.')[0]\n",
        "    ckpt = os.path.join(model_dir, ckpt_name)\n",
        "    \n",
        "    # Ensure dimensions and sampling rates are equal\n",
        "    time_steps_train = gin.query_parameter('DefaultPreprocessor.time_steps')\n",
        "    n_samples_train = gin.query_parameter('Additive.n_samples')\n",
        "    hop_size = int(n_samples_train / time_steps_train)\n",
        "    \n",
        "    time_steps = int(audio.shape[1] / hop_size)\n",
        "    n_samples = time_steps * hop_size\n",
        "    \n",
        "    # print(\"===Trained model===\")\n",
        "    # print(\"Time Steps\", time_steps_train)\n",
        "    # print(\"Samples\", n_samples_train)\n",
        "    # print(\"Hop Size\", hop_size)\n",
        "    # print(\"\\n===Resynthesis===\")\n",
        "    # print(\"Time Steps\", time_steps)\n",
        "    # print(\"Samples\", n_samples)\n",
        "    # print('')\n",
        "    \n",
        "    gin_params = [\n",
        "        'RnnFcDecoder.input_keys = (\"f0_scaled\", \"ld_scaled\")',\n",
        "        'Additive.n_samples = {}'.format(n_samples),\n",
        "        'FilteredNoise.n_samples = {}'.format(n_samples),\n",
        "        'DefaultPreprocessor.time_steps = {}'.format(time_steps),\n",
        "    ]\n",
        "    \n",
        "    with gin.unlock_config():\n",
        "      gin.parse_config(gin_params)\n",
        "    \n",
        "    \n",
        "    # Trim all input vectors to correct lengths \n",
        "    for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
        "      audio_features[key] = audio_features[key][:time_steps]\n",
        "    audio_features['audio'] = audio_features['audio'][:, :n_samples]\n",
        "    \n",
        "    \n",
        "    # Set up the model just to predict audio given new conditioning\n",
        "    model = ddsp.training.models.Autoencoder()\n",
        "    model.restore(ckpt)\n",
        "    \n",
        "    # Build model by running a batch through it.\n",
        "    start_time = time.time()\n",
        "    _ = model(audio_features, training=False)\n",
        "    print('Restoring model took %.1f seconds' % (time.time() - start_time))\n",
        "    #return audio_features\n",
        "print('DONE')# @title P4 MODEL\n",
        "    \n",
        "# model = null\n",
        "# 'Violin' #@param ['Violin', 'Flute', 'Flute2', 'Trumpet', 'Tenor_Saxophone','Upload your own (checkpoint folder as .zip)']\n",
        "# MODEL = model\n",
        "DATASET_STATS = None\n",
        "def p4model(m):\n",
        "    global audio_features_mod, audio, audio_features, DATASET_STATS\n",
        "    global model, MODEL\n",
        "    model = m\n",
        "    MODEL = m\n",
        "    #audio_features = modified\n",
        "    GCS_CKPT_DIR = 'gs://ddsp/models/tf2'\n",
        "    print(\"m\", m, \"model\", model, \"MODEL\", MODEL)\n",
        "    if model in ('Violin', 'Flute', 'Flute2', 'Trumpet', 'Tenor_Saxophone'):\n",
        "        # Pretrained models.\n",
        "        PRETRAINED_DIR = '/content/pretrained'\n",
        "        # Copy over from gs:// for faster loading.\n",
        "        !rm -r $PRETRAINED_DIR &> /dev/null\n",
        "        !mkdir $PRETRAINED_DIR &> /dev/null\n",
        "        GCS_CKPT_DIR = 'gs://ddsp/models/tf2'\n",
        "        model_dir = os.path.join(GCS_CKPT_DIR, 'solo_%s_ckpt' % model.lower())\n",
        "        \n",
        "        !gsutil cp $model_dir/* $PRETRAINED_DIR &> /dev/null\n",
        "        model_dir = PRETRAINED_DIR\n",
        "        gin_file = os.path.join(model_dir, 'operative_config-0.gin')\n",
        "    \n",
        "        # Load the dataset statistics.\n",
        "    DATASET_STATS = None\n",
        "    dataset_stats_file = os.path.join(model_dir, 'dataset_statistics.pkl')\n",
        "    print(f'Loading dataset statistics from {dataset_stats_file}')\n",
        "    try:\n",
        "      if tf.io.gfile.exists(dataset_stats_file):\n",
        "        with tf.io.gfile.GFile(dataset_stats_file, 'rb') as f:\n",
        "          DATASET_STATS = pickle.load(f)\n",
        "    except Exception as err:\n",
        "      print('Loading dataset statistics from pickle failed: {}.'.format(err))\n",
        "\n",
        "    # Parse gin config,\n",
        "    with gin.unlock_config():\n",
        "      gin.parse_config_file(gin_file, skip_unknown=True)\n",
        "    \n",
        "    # Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
        "    ckpt_files = [f for f in tf.io.gfile.listdir(model_dir) if 'ckpt' in f]\n",
        "    ckpt_name = ckpt_files[0].split('.')[0]\n",
        "    ckpt = os.path.join(model_dir, ckpt_name)\n",
        "    \n",
        "    # Ensure dimensions and sampling rates are equal\n",
        "    time_steps_train = gin.query_parameter('DefaultPreprocessor.time_steps')\n",
        "    n_samples_train = gin.query_parameter('Additive.n_samples')\n",
        "    hop_size = int(n_samples_train / time_steps_train)\n",
        "    \n",
        "    time_steps = int(audio.shape[1] / hop_size)\n",
        "    n_samples = time_steps * hop_size\n",
        "    \n",
        "    # print(\"===Trained model===\")\n",
        "    # print(\"Time Steps\", time_steps_train)\n",
        "    # print(\"Samples\", n_samples_train)\n",
        "    # print(\"Hop Size\", hop_size)\n",
        "    # print(\"\\n===Resynthesis===\")\n",
        "    # print(\"Time Steps\", time_steps)\n",
        "    # print(\"Samples\", n_samples)\n",
        "    # print('')\n",
        "    \n",
        "    gin_params = [\n",
        "        'RnnFcDecoder.input_keys = (\"f0_scaled\", \"ld_scaled\")',\n",
        "        'Additive.n_samples = {}'.format(n_samples),\n",
        "        'FilteredNoise.n_samples = {}'.format(n_samples),\n",
        "        'DefaultPreprocessor.time_steps = {}'.format(time_steps),\n",
        "    ]\n",
        "    \n",
        "    with gin.unlock_config():\n",
        "      gin.parse_config(gin_params)\n",
        "    \n",
        "    \n",
        "    # Trim all input vectors to correct lengths \n",
        "    for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
        "      audio_features[key] = audio_features[key][:time_steps]\n",
        "    audio_features['audio'] = audio_features['audio'][:, :n_samples]\n",
        "    \n",
        "    \n",
        "    # Set up the model just to predict audio given new conditioning\n",
        "    model = ddsp.training.models.Autoencoder()\n",
        "    model.restore(ckpt)\n",
        "    \n",
        "    # Build model by running a batch through it.\n",
        "    start_time = time.time()\n",
        "    _ = model(audio_features, training=False)\n",
        "    print('Restoring model took %.1f seconds' % (time.time() - start_time))\n",
        "    #return audio_features\n",
        "#@ title p4 MODIFY { output-height: 400 }\n",
        "## Helper functions.\n",
        "def shift_ld(audio_features, ld_shift=0.0):\n",
        "  \"\"\"Shift loudness by a number of ocatves.\"\"\"\n",
        "  audio_features['loudness_db'] += ld_shift\n",
        "  return audio_features\n",
        "\n",
        "\n",
        "def shift_f0(audio_features, f0_octave_shift=0.0):\n",
        "  \"\"\"Shift f0 by a number of ocatves.\"\"\"\n",
        "  audio_features['f0_hz'] *= 2.0 ** (f0_octave_shift)\n",
        "  audio_features['f0_hz'] = np.clip(audio_features['f0_hz'], \n",
        "                                    0.0, \n",
        "                                    librosa.midi_to_hz(110.0))\n",
        "  return audio_features\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def p4modify( octave, loudness, threshold, autoadjust,  autotune, quiet):\n",
        "  global audio_features_mod, audio_features, DATASET_STATS\n",
        "  audio_features_mod = {k: v.copy() for k, v in audio_features.items()}\n",
        "  audio_features_mod = shift_ld(audio_features_mod, loudness)\n",
        "  audio_features_mod = shift_f0(audio_features_mod, octave)\n",
        "  #return audio_features_mod\n",
        "  if autoadjust and DATASET_STATS is not None:\n",
        "    # Detect sections that are \"on\".\n",
        "    mask_on, note_on_value = detect_notes(audio_features['loudness_db'],\n",
        "                                          audio_features['f0_confidence'],\n",
        "                                          threshold)\n",
        "\n",
        "    if np.any(mask_on):\n",
        "      # Shift the pitch register.\n",
        "      target_mean_pitch = DATASET_STATS['mean_pitch']\n",
        "      pitch = ddsp.core.hz_to_midi(audio_features['f0_hz'])\n",
        "      mean_pitch = np.mean(pitch[mask_on])\n",
        "      p_diff = target_mean_pitch - mean_pitch\n",
        "      p_diff_octave = p_diff / 12.0\n",
        "      round_fn = np.floor if p_diff_octave > 1.5 else np.ceil\n",
        "      p_diff_octave = round_fn(p_diff_octave)\n",
        "      audio_features_mod = shift_f0(audio_features_mod, p_diff_octave)\n",
        "\n",
        "\n",
        "      # Quantile shift the note_on parts.\n",
        "      _, loudness_norm = colab_utils.fit_quantile_transform(\n",
        "          audio_features['loudness_db'],\n",
        "          mask_on,\n",
        "          inv_quantile=DATASET_STATS['quantile_transform'])\n",
        "\n",
        "      # Turn down the note_off parts.\n",
        "      mask_off = np.logical_not(mask_on)\n",
        "      loudness_norm[mask_off] -=  quiet * (1.0 - note_on_value[mask_off][:, np.newaxis])\n",
        "      loudness_norm = np.reshape(loudness_norm, audio_features['loudness_db'].shape)\n",
        "      \n",
        "      audio_features_mod['loudness_db'] = loudness_norm \n",
        "\n",
        "      # Auto-tune.\n",
        "      if autotune:\n",
        "        f0_midi = np.array(ddsp.core.hz_to_midi(audio_features_mod['f0_hz']))\n",
        "        tuning_factor = get_tuning_factor(f0_midi, audio_features_mod['f0_confidence'], mask_on)\n",
        "        f0_midi_at = auto_tune(f0_midi, tuning_factor, mask_on, amount=autotune)\n",
        "        audio_features_mod['f0_hz'] = ddsp.core.midi_to_hz(f0_midi_at)\n",
        "    \n",
        "\n",
        "  \n",
        "print('DONE')\n",
        "\n",
        "\n",
        "#^^^^MODIFIED NOTEBOOK\n",
        "\n",
        "def create_audio_file(array_of_floats, path):\n",
        "    if len(array_of_floats.shape) == 2:\n",
        "        array_of_floats = array_of_floats[0]\n",
        "    normalizer = float(np.iinfo(np.int16).max)\n",
        "    array_of_ints = np.array(\n",
        "        np.asarray(array_of_floats) * normalizer, dtype=np.int16)\n",
        "    memfile = io.BytesIO()\n",
        "    wavfile.write(path, sample_rate, array_of_ints)\n",
        "    memfile.close()\n",
        "    print(\"SAVED FILE\")\n",
        "\n",
        "\n",
        "def p4makeSave2(path):\n",
        "  global audio_features_mod, audio_features, audio, count, gdID\n",
        "  af = audio_features if audio_features_mod is None else audio_features_mod\n",
        "  # Run a batch of predictions.\n",
        "  start_time = time.time()\n",
        "  # print(mAudio, type(mAudio))\n",
        "  print(af)\n",
        "  audio_gen = model(af, training=False)\n",
        "  play(audio_gen)\n",
        "  specplot(audio_gen)\n",
        "  print('Prediction took %.1f seconds' % (time.time() - start_time))\n",
        "  create_audio_file(audio_gen, path)\n",
        "  # uploaded = drive.CreateFile({'title': 'Sample upload.txt'})\n",
        "  # uploaded.SetContentString('Sample upload file content')\n",
        "  # uploaded.Upload()\n",
        "  # print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "  TTdfile = drive.CreateFile(\n",
        "            {'parents': [{'id': gdID}], 'title': 'ddspd' + str(count) + '.wav'})\n",
        "            \n",
        "  TTdfile.SetContentFile(path)\n",
        "  TTdfile.Upload()\n",
        "print('DONE')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpO0nsqciyKk",
        "colab_type": "text"
      },
      "source": [
        "This continously checks for new files in Google Drive, processes them, and uploaded the transferred audio."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM12QUzU5hdP",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title LOOP\n",
        "count = 0\n",
        "found = False\n",
        "while True:\n",
        "  global count, found\n",
        "  # FIND JSON\n",
        "  if not found:\n",
        "    file_list = drive.ListFile(\n",
        "              {'q':  \"'\" + gdID + \"'\" + \" in parents and trashed=false and title = '\" + \"settings\" + str(count) + \".json\" + \"'\"}).GetList()\n",
        "    for file1 in file_list:\n",
        "        print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
        "        # dlfile = drive.CreateFile({'id': file1['id']})\n",
        "        # dlfile.GetContentFile(file1)\n",
        "        downloaded = drive.CreateFile({'id': file1['id']})\n",
        "        print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))\n",
        "        jf = json.loads(downloaded.GetContentString())\n",
        "        print('time passed:', ((time.time()) % 86400) - jf[\"time\"])\n",
        "        found = True\n",
        "\n",
        "  # LOAD AUDIO\n",
        "  file_list = drive.ListFile(\n",
        "            {'q':  \"'\" + gdID + \"'\" + \" in parents and trashed=false and title = '\" + \"sendAudio\" + str(count) + \".wav\" + \"'\"}).GetList()\n",
        "  for file1 in file_list:\n",
        "      print('title: %s, id: %s' % (file1['title'], file1['id']))\n",
        "      # dlfile = drive.CreateFile({'id': file1['id']})\n",
        "      # dlfile.GetContentFile(file1)\n",
        "      aud = drive.CreateFile({'id': file1['id']})\n",
        "      aud.GetContentFile(\"ddsp\" + str(count) + \".wav\")\n",
        "      \n",
        "      \n",
        "      p4load(\"ddsp\" + str(count) + \".wav\")\n",
        "      play(audio)\n",
        "      print(\"model from json is\", jf[\"model\"])  \n",
        "      p4model(jf[\"model\"])\n",
        "      \n",
        "      p4modify( jf[\"octave\"], jf[\"loudness\"], jf[\"threshold\"], jf[\"auto\"], jf[\"autotune\"],jf[\"quiet\"] )\n",
        "      \n",
        "      p4makeSave2((\"audio-transferred\" + str(count) + '.wav'))\n",
        "      count = count + 1\n",
        "      found = False\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}